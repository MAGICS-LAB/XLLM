{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jys3649/miniconda3/envs/xllm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 14/14 [01:12<00:00,  5.15s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"ehartford/Wizard-Vicuna-30B-Uncensored\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "use_fast_tokenizer = \"LlamaForCausalLM\" not in model.config.architectures\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=use_fast_tokenizer, padding_side=\"left\", legacy=False)\n",
    "tokenizer.pad_token_id = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tag = \"USER:\"\n",
    "assistant_tag = \"ASSISTANT:\"\n",
    "string = \"Hello, how are you doing today?\"\n",
    "connected_string = user_tag + string + assistant_tag\n",
    "inputs = tokenizer(connected_string, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs =  model(**inputs, output_hidden_states=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'hidden_states'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.9165e-02, -3.9368e-03, -1.0757e-03,  ...,  2.2583e-03,\n",
       "           -2.1210e-03, -1.5991e-02],\n",
       "          [-1.7944e-02, -1.1230e-02, -1.6724e-02,  ...,  3.5553e-03,\n",
       "           -1.3306e-02, -1.7456e-02],\n",
       "          [ 3.3203e-02,  1.6479e-02, -2.1820e-03,  ..., -8.9722e-03,\n",
       "            1.1597e-02, -2.2705e-02],\n",
       "          ...,\n",
       "          [ 2.5482e-03, -4.6387e-03, -8.2397e-03,  ...,  3.8300e-03,\n",
       "           -4.2677e-05,  2.9541e-02],\n",
       "          [ 1.8066e-02,  2.6131e-04,  2.0020e-02,  ...,  2.0386e-02,\n",
       "           -1.3916e-02,  1.3809e-03],\n",
       "          [ 9.5215e-03, -9.5215e-03, -2.4292e-02,  ..., -1.3794e-02,\n",
       "           -7.4158e-03,  7.4768e-03]]], dtype=torch.float16,\n",
       "        grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[ 0.1165,  0.0781, -0.0547,  ...,  0.1068,  0.0484, -0.0319],\n",
       "          [-0.0606, -0.0208, -0.0618,  ..., -0.0184, -0.0043,  0.0408],\n",
       "          [ 0.0877,  0.0605,  0.0108,  ..., -0.0919,  0.0570, -0.0388],\n",
       "          ...,\n",
       "          [-0.0247,  0.0174, -0.0890,  ...,  0.0080,  0.0312,  0.0662],\n",
       "          [ 0.0396,  0.0422,  0.0154,  ..., -0.0037,  0.0066,  0.0028],\n",
       "          [ 0.0008, -0.0208, -0.0547,  ..., -0.0345, -0.0273,  0.0114]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[ 0.1224,  0.1562,  0.0368,  ...,  0.1362,  0.1865, -0.0181],\n",
       "          [-0.1017,  0.0205, -0.1156,  ..., -0.0431, -0.0591,  0.0188],\n",
       "          [ 0.0933,  0.0851,  0.0337,  ..., -0.1252, -0.0505, -0.1028],\n",
       "          ...,\n",
       "          [ 0.0012, -0.0008, -0.0661,  ...,  0.0102, -0.0246,  0.1350],\n",
       "          [-0.0516,  0.0696,  0.0078,  ..., -0.1353, -0.0663,  0.1554],\n",
       "          [-0.0740, -0.0398, -0.1099,  ..., -0.0953, -0.0499,  0.0370]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[ 0.0941,  0.2534, -0.0271,  ...,  0.1321,  0.2549, -0.0145],\n",
       "          [-0.2037,  0.0310, -0.0311,  ..., -0.0112, -0.0707, -0.0642],\n",
       "          [ 0.0403,  0.0412,  0.0959,  ..., -0.0841, -0.1044, -0.0610],\n",
       "          ...,\n",
       "          [ 0.0094, -0.0294, -0.0731,  ..., -0.1456,  0.0290,  0.0824],\n",
       "          [-0.0022,  0.0861,  0.0522,  ..., -0.2405,  0.0979,  0.4878],\n",
       "          [-0.0349, -0.0670, -0.0250,  ..., -0.1680, -0.0407,  0.0007]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.1279,  1.0479, -0.2258,  ...,  0.4751,  1.1016, -0.5425],\n",
       "          [-0.2196,  0.0168, -0.0048,  ..., -0.0527, -0.0603, -0.0520],\n",
       "          [ 0.0639,  0.0263,  0.1681,  ..., -0.1085, -0.2676, -0.1564],\n",
       "          ...,\n",
       "          [-0.0458, -0.1016, -0.1886,  ..., -0.1631, -0.1646,  0.1902],\n",
       "          [ 0.0229, -0.0111, -0.0348,  ..., -0.2627, -0.0309,  0.5122],\n",
       "          [-0.0688, -0.1005,  0.0283,  ..., -0.2046, -0.1187,  0.0485]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.1218,  1.0674, -0.2450,  ...,  0.4741,  1.1250, -0.5649],\n",
       "          [-0.3357,  0.0224, -0.1509,  ..., -0.0215, -0.0393, -0.0691],\n",
       "          [ 0.0168,  0.0797,  0.1654,  ..., -0.0371, -0.3291, -0.1266],\n",
       "          ...,\n",
       "          [ 0.0201, -0.1759, -0.2185,  ..., -0.2450, -0.1437,  0.2350],\n",
       "          [ 0.0079, -0.0231, -0.0917,  ..., -0.3865,  0.0222,  0.6196],\n",
       "          [-0.0354, -0.0926, -0.0031,  ..., -0.0884, -0.1620,  0.0429]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.1077,  1.0674, -0.2615,  ...,  0.4824,  1.1445, -0.5669],\n",
       "          [-0.3167,  0.0188, -0.2148,  ..., -0.0911,  0.0566, -0.0524],\n",
       "          [-0.1217, -0.0873,  0.3357,  ..., -0.1273, -0.3591, -0.2625],\n",
       "          ...,\n",
       "          [ 0.0623, -0.1172, -0.2686,  ..., -0.3516, -0.0169,  0.0714],\n",
       "          [ 0.0534,  0.0286,  0.0030,  ..., -0.4709,  0.0913,  0.5156],\n",
       "          [ 0.0219, -0.0460,  0.0112,  ..., -0.2120, -0.0930, -0.0389]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.0956,  1.1035, -0.2306,  ...,  0.4849,  1.1621, -0.5566],\n",
       "          [-0.3259,  0.1594, -0.3318,  ..., -0.2451, -0.0364, -0.3140],\n",
       "          [-0.2306, -0.0457,  0.4717,  ..., -0.2314, -0.3145, -0.4365],\n",
       "          ...,\n",
       "          [ 0.0770, -0.0043, -0.2085,  ..., -0.2529, -0.1429,  0.0324],\n",
       "          [-0.2141,  0.1191, -0.2007,  ..., -0.3994, -0.0861,  0.6763],\n",
       "          [-0.1133,  0.0390, -0.0402,  ..., -0.1996, -0.0251, -0.1162]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.0898,  1.1387, -0.2201,  ...,  0.4797,  1.1475, -0.5327],\n",
       "          [-0.3765,  0.1161, -0.3513,  ..., -0.3262,  0.0825, -0.3179],\n",
       "          [-0.2634, -0.0945,  0.4727,  ..., -0.2446, -0.2537, -0.3259],\n",
       "          ...,\n",
       "          [-0.0405,  0.0951, -0.2136,  ..., -0.3157,  0.0549, -0.1306],\n",
       "          [-0.2477,  0.2443, -0.2661,  ..., -0.4146, -0.0415,  0.6431],\n",
       "          [-0.1770,  0.1619, -0.0998,  ..., -0.2189, -0.1343, -0.0278]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.0753,  1.1875, -0.1567,  ...,  0.4822,  1.1367, -0.5044],\n",
       "          [-0.1753, -0.0079, -0.1401,  ..., -0.4712,  0.2039, -0.3672],\n",
       "          [-0.3794, -0.2058,  0.4744,  ..., -0.3496, -0.2812, -0.4409],\n",
       "          ...,\n",
       "          [-0.0798, -0.0132, -0.1711,  ..., -0.2698, -0.0078, -0.0029],\n",
       "          [-0.3748,  0.3691, -0.1812,  ..., -0.2563, -0.2415,  0.5566],\n",
       "          [-0.3140,  0.0657, -0.0373,  ..., -0.1777, -0.3750,  0.1121]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.0502,  1.0430, -0.0253,  ...,  0.4868,  1.1514, -0.3467],\n",
       "          [ 0.1741,  0.4524,  0.4626,  ..., -0.5068,  0.2408, -0.2233],\n",
       "          [-0.0398, -0.0694,  0.5864,  ..., -0.2400, -0.1099, -0.4805],\n",
       "          ...,\n",
       "          [-0.2866,  0.0606, -0.1399,  ..., -0.2964,  0.1912, -0.0178],\n",
       "          [-0.5288,  0.4932, -0.1188,  ..., -0.2949, -0.1760,  0.4492],\n",
       "          [-0.5161,  0.1035,  0.1454,  ..., -0.1819, -0.3994,  0.0781]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.6406,  1.1191,  0.4624,  ...,  0.5615,  1.2852,  0.1011],\n",
       "          [ 0.1765,  0.1149,  0.1809,  ..., -0.5166,  0.1553, -0.0656],\n",
       "          [ 0.0275, -0.2030,  0.5835,  ..., -0.3555, -0.1655, -0.4644],\n",
       "          ...,\n",
       "          [-0.1492,  0.1246, -0.1226,  ..., -0.2786,  0.1298, -0.0463],\n",
       "          [-0.7183,  0.7651, -0.3333,  ..., -0.1005, -0.3909,  0.4924],\n",
       "          [-0.4399,  0.2273,  0.0143,  ..., -0.0853, -0.3486,  0.0732]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.6138,  1.1719,  0.5181,  ...,  0.5239,  1.2852,  0.0538],\n",
       "          [ 0.3867, -0.1086,  0.1388,  ..., -0.5342,  0.0592, -0.2050],\n",
       "          [ 0.1885, -0.3867,  0.4302,  ..., -0.2993, -0.2327, -0.4905],\n",
       "          ...,\n",
       "          [-0.0786,  0.2129, -0.3269,  ..., -0.0347,  0.0869, -0.1032],\n",
       "          [-0.8936,  0.7295, -0.2240,  ...,  0.1777, -0.5757,  0.3005],\n",
       "          [-0.4863, -0.1688, -0.0765,  ..., -0.1158, -0.3254, -0.0209]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.5562,  1.1445,  0.6011,  ...,  0.4639,  1.3350,  0.0306],\n",
       "          [ 0.5547, -0.1628,  0.0388,  ..., -0.5908, -0.0846, -0.1700],\n",
       "          [ 0.2013, -0.3318,  0.3274,  ..., -0.2490, -0.1841, -0.5483],\n",
       "          ...,\n",
       "          [-0.1599,  0.0999, -0.1466,  ...,  0.1021,  0.2429, -0.1555],\n",
       "          [-0.9268,  0.7207, -0.0310,  ...,  0.4907, -0.4314,  0.0083],\n",
       "          [-0.6558, -0.2705,  0.0117,  ..., -0.0092, -0.2377, -0.0676]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.5469,  1.1494,  0.6479,  ...,  0.4070,  1.2451,  0.0085],\n",
       "          [ 0.3589, -0.4473, -0.2440,  ..., -0.8159, -0.2617, -0.0088],\n",
       "          [ 0.2301, -0.6074,  0.3206,  ..., -0.3228, -0.2072, -0.5972],\n",
       "          ...,\n",
       "          [ 0.1177,  0.1602, -0.3296,  ..., -0.1105,  0.1343, -0.1855],\n",
       "          [-0.6035,  0.6587, -0.1992,  ...,  0.3816, -0.5498, -0.2871],\n",
       "          [-0.6616, -0.1138,  0.0409,  ..., -0.1123, -0.5103, -0.2583]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.5679,  1.1328,  0.6738,  ...,  0.4094,  1.1182, -0.0743],\n",
       "          [ 0.3887, -0.4041, -0.2861,  ..., -1.1406, -0.3406,  0.0992],\n",
       "          [ 0.1927, -0.6611,  0.3384,  ..., -0.3291, -0.2893, -0.5850],\n",
       "          ...,\n",
       "          [ 0.2651,  0.1041, -0.3472,  ...,  0.0782,  0.2676,  0.0597],\n",
       "          [-0.3550,  0.5581, -0.4004,  ...,  0.4966, -0.2966, -0.0192],\n",
       "          [-0.3870, -0.4863, -0.0760,  ..., -0.2583, -0.1965,  0.1549]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.7407,  0.8232,  0.5117,  ...,  0.6069,  1.2070, -0.1765],\n",
       "          [ 0.7109, -0.5732, -0.1414,  ..., -0.9663, -0.1831,  0.2209],\n",
       "          [ 0.3096, -0.3635,  0.6709,  ..., -0.3120, -0.4634, -0.6040],\n",
       "          ...,\n",
       "          [ 0.1583, -0.2556, -0.1061,  ...,  0.1166, -0.0759, -0.0852],\n",
       "          [-0.5107,  0.1685, -0.0931,  ...,  0.7583, -0.7246, -0.3872],\n",
       "          [-0.5381, -0.7920,  0.0392,  ...,  0.0867, -0.4878, -0.1458]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.7207,  0.8594,  0.5303,  ...,  0.5454,  1.2002, -0.2024],\n",
       "          [ 0.6089, -0.5942, -0.4631,  ..., -0.9365, -0.1726,  0.2561],\n",
       "          [ 0.3962, -0.4131,  0.7373,  ..., -0.4717, -0.4124, -0.7979],\n",
       "          ...,\n",
       "          [-0.3401, -0.1945, -0.0545,  ...,  0.0260, -0.2532, -0.0778],\n",
       "          [-0.6118,  0.2368, -0.2788,  ...,  0.6475, -0.6934, -0.2561],\n",
       "          [-1.0420, -1.1406,  0.0235,  ..., -0.1554, -0.3223,  0.0304]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.6719,  0.8525,  0.5068,  ...,  0.5718,  1.2012, -0.1688],\n",
       "          [ 0.4438, -0.5879, -0.3184,  ..., -0.9180, -0.0149,  0.1375],\n",
       "          [ 0.2852, -0.4587,  0.8101,  ..., -0.4451, -0.4084, -0.5850],\n",
       "          ...,\n",
       "          [-0.0521, -0.1530,  0.1987,  ..., -0.2198, -0.1833,  0.1833],\n",
       "          [-0.5635,  0.0400, -0.4006,  ...,  0.5874, -0.8125,  0.0562],\n",
       "          [-1.0977, -1.6377, -0.0190,  ..., -0.0469, -0.2554,  0.3921]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.7212,  0.8936,  0.5200,  ...,  0.5176,  1.1494, -0.3040],\n",
       "          [ 0.1987, -0.1418, -0.3516,  ..., -0.8262,  0.2769, -0.0105],\n",
       "          [ 0.0708, -0.5894,  0.5425,  ..., -0.6250, -0.4878, -0.7832],\n",
       "          ...,\n",
       "          [-0.0171, -0.1943,  0.2573,  ..., -0.3079, -0.6055, -0.0133],\n",
       "          [-0.4568,  0.1237, -0.3613,  ...,  0.3823, -0.9521, -0.0768],\n",
       "          [-1.3613, -1.4561, -0.1907,  ..., -0.1622, -0.1279,  0.4617]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-8.6084e-01,  8.8672e-01,  5.3955e-01,  ...,  5.3516e-01,\n",
       "            1.0840e+00, -2.2144e-01],\n",
       "          [ 2.5000e-01, -3.5864e-01, -2.0459e-01,  ..., -8.5547e-01,\n",
       "            3.3130e-01, -1.1597e-03],\n",
       "          [ 7.8857e-02, -4.0723e-01,  7.3926e-01,  ..., -3.5352e-01,\n",
       "           -5.5713e-01, -8.6475e-01],\n",
       "          ...,\n",
       "          [-1.2476e-01, -1.1963e-02,  1.9470e-01,  ..., -1.1145e-01,\n",
       "           -4.6631e-01,  8.3496e-02],\n",
       "          [-4.4141e-01,  2.4829e-01, -1.2781e-01,  ...,  5.3467e-01,\n",
       "           -1.0176e+00,  5.9814e-02],\n",
       "          [-1.1113e+00, -1.2041e+00, -7.9407e-02,  ...,  1.0034e-01,\n",
       "           -1.1487e-01,  3.9600e-01]]], dtype=torch.float16,\n",
       "        grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.8198,  0.8198,  0.5117,  ...,  0.6362,  1.1377, -0.1759],\n",
       "          [ 0.4048, -0.1820, -0.4463,  ..., -0.8984,  0.2255,  0.0472],\n",
       "          [-0.0309, -0.2345,  0.5625,  ..., -0.1796, -0.5723, -1.1992],\n",
       "          ...,\n",
       "          [-0.1512,  0.3093, -0.1392,  ...,  0.0669, -0.6016, -0.0692],\n",
       "          [-0.4204,  0.3774, -0.3804,  ...,  0.6216, -1.1064, -0.2822],\n",
       "          [-0.8896, -0.9966, -0.2881,  ...,  0.4253, -0.0828,  0.1821]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.8843,  0.7891,  0.4268,  ...,  0.6948,  1.1328, -0.1240],\n",
       "          [ 0.1040, -0.2617, -0.1042,  ..., -1.0381,  0.3533,  0.1229],\n",
       "          [-0.2656, -0.3745,  0.4053,  ..., -0.5884, -0.7905, -0.9707],\n",
       "          ...,\n",
       "          [-0.2869,  0.2942,  0.0790,  ..., -0.1152, -0.2935, -0.1064],\n",
       "          [-0.4590,  0.2128, -0.2241,  ...,  0.1721, -0.9741, -0.4233],\n",
       "          [-0.6543, -1.0234, -0.1871,  ...,  0.3909, -0.2571,  0.4756]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.8276,  0.7212,  0.3901,  ...,  0.7578,  1.1250, -0.0797],\n",
       "          [-0.0768, -0.4824, -0.3389,  ..., -0.9229,  0.3965,  0.0331],\n",
       "          [-0.4165, -0.3552,  0.5083,  ..., -0.5547, -0.8145, -1.0156],\n",
       "          ...,\n",
       "          [-0.3191,  0.2893, -0.3423,  ..., -0.0114, -0.2283,  0.1489],\n",
       "          [-0.5996,  0.0247, -0.4209,  ...,  0.2817, -0.7178, -0.1243],\n",
       "          [-0.3997, -1.1855, -0.1702,  ...,  0.3455,  0.0342,  0.6157]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.8379,  0.7446,  0.3428,  ...,  0.8164,  1.0762, -0.0803],\n",
       "          [ 0.0176, -0.2286, -0.1871,  ..., -0.5664,  0.3054, -0.1192],\n",
       "          [-0.3242, -0.4092,  0.4500,  ..., -0.5215, -1.2012, -0.8750],\n",
       "          ...,\n",
       "          [-0.1353,  0.4512, -0.7773,  ..., -0.3818, -0.1416,  0.0781],\n",
       "          [-0.1580,  0.0676, -0.7314,  ...,  0.0561, -0.7466,  0.1804],\n",
       "          [-0.4021, -1.6230,  0.1804,  ...,  0.1182,  0.1687,  0.4636]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.7993,  0.6992,  0.2695,  ...,  0.7852,  1.0166, -0.0766],\n",
       "          [ 0.1975, -0.4722, -0.3018,  ..., -0.3350,  0.0189,  0.0679],\n",
       "          [-0.2256, -0.1033,  0.4270,  ..., -0.3689, -1.3525, -0.9902],\n",
       "          ...,\n",
       "          [-0.0400,  0.5747, -0.8477,  ..., -0.1941, -0.0328,  0.2386],\n",
       "          [-0.2737,  0.1837, -0.7412,  ...,  0.0270, -0.6436,  0.3176],\n",
       "          [-0.0040, -1.7500,  0.0254,  ..., -0.1237,  0.1864,  0.2107]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.2295,  0.5649, -0.1060,  ...,  0.7715,  1.2881, -0.3354],\n",
       "          [ 0.1027, -0.1785, -0.3149,  ...,  0.1958, -0.3057,  0.0889],\n",
       "          [-0.2839,  0.1691,  0.6924,  ..., -0.4111, -0.9888, -1.2266],\n",
       "          ...,\n",
       "          [ 0.0828,  0.7007, -0.4839,  ...,  0.1202,  0.1799,  0.3745],\n",
       "          [-0.2881,  0.1606, -0.5073,  ...,  0.2043, -0.6807,  0.5449],\n",
       "          [ 0.2593, -1.7109,  0.0299,  ...,  0.0020, -0.0245,  0.2954]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1943,  0.5127, -0.0806,  ...,  0.7109,  1.2432, -0.3823],\n",
       "          [-0.0242, -0.1530, -0.3782,  ..., -0.1132, -0.4521,  0.0457],\n",
       "          [-0.0651,  0.2795,  0.5728,  ..., -0.7183, -0.9971, -1.2754],\n",
       "          ...,\n",
       "          [ 0.3755,  0.8008, -0.8325,  ...,  0.0892,  0.1862,  0.7607],\n",
       "          [-0.2109,  0.2345, -0.5073,  ...,  0.2576, -0.9307,  0.9409],\n",
       "          [ 0.4229, -1.6885, -0.0749,  ..., -0.0433, -0.0220,  0.1163]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1904e+00,  4.8950e-01, -8.4045e-02,  ...,  7.4854e-01,\n",
       "            1.2568e+00, -3.0469e-01],\n",
       "          [-2.9858e-01, -3.2080e-01, -3.0518e-01,  ...,  1.6907e-02,\n",
       "           -1.7651e-01, -3.6475e-01],\n",
       "          [ 8.6975e-02,  1.6858e-01,  4.2139e-01,  ..., -8.5498e-01,\n",
       "           -5.9082e-01, -9.3506e-01],\n",
       "          ...,\n",
       "          [ 2.2925e-01,  6.2988e-01, -6.8945e-01,  ...,  2.6172e-01,\n",
       "            6.2695e-01,  1.0381e+00],\n",
       "          [-4.6973e-01,  2.3047e-01, -3.0884e-01,  ...,  5.1172e-01,\n",
       "           -6.2402e-01,  1.2920e+00],\n",
       "          [ 4.7217e-01, -1.5244e+00,  2.7124e-01,  ..., -3.7354e-01,\n",
       "           -1.4648e-01,  1.4648e-03]]], dtype=torch.float16,\n",
       "        grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.2354,  0.4807, -0.0356,  ...,  0.7588,  1.2432, -0.3262],\n",
       "          [-0.2261, -0.2720, -0.6094,  ...,  0.0593, -0.4482, -0.4575],\n",
       "          [-0.0236,  0.3687,  0.3020,  ..., -1.1562, -0.6621, -1.0029],\n",
       "          ...,\n",
       "          [ 0.4014,  0.6431, -0.9492,  ...,  0.0907,  0.6255,  1.1826],\n",
       "          [-0.3635,  0.5317, -0.1443,  ...,  0.4084, -0.8325,  1.4277],\n",
       "          [ 0.7402, -1.1689, -0.0410,  ..., -0.3137, -0.0999,  0.2559]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1367,  0.4617, -0.0820,  ...,  0.7578,  1.2285, -0.2834],\n",
       "          [-0.3870, -0.0768, -0.6631,  ...,  0.1428, -0.4023, -0.0579],\n",
       "          [-0.3535,  0.3010,  0.4456,  ..., -1.1816, -0.4727, -0.8584],\n",
       "          ...,\n",
       "          [ 0.0459,  0.7627, -1.1016,  ..., -0.1555,  0.5947,  0.7783],\n",
       "          [-0.7451,  0.4792, -0.2251,  ...,  0.3491, -1.2637,  1.3369],\n",
       "          [ 0.3606, -1.4053, -0.0320,  ..., -0.2915, -0.0386,  0.1575]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1279e+00,  4.3457e-01, -8.1421e-02,  ...,  7.3438e-01,\n",
       "            1.2295e+00, -2.7954e-01],\n",
       "          [-3.2837e-01, -2.3706e-01, -8.2617e-01,  ...,  6.9531e-01,\n",
       "           -6.3623e-01, -6.1035e-04],\n",
       "          [-3.4692e-01,  2.4915e-01,  4.6875e-02,  ..., -1.1318e+00,\n",
       "           -4.0210e-01, -8.6230e-01],\n",
       "          ...,\n",
       "          [ 3.6572e-01,  7.6660e-01, -1.3555e+00,  ..., -2.6465e-01,\n",
       "            4.1382e-01,  7.1973e-01],\n",
       "          [-5.2246e-01,  6.2109e-01, -4.1089e-01,  ...,  2.8003e-01,\n",
       "           -1.2959e+00,  1.3818e+00],\n",
       "          [ 6.2842e-01, -1.3232e+00,  3.4033e-01,  ..., -8.8477e-01,\n",
       "           -1.4722e-01,  1.9922e-01]]], dtype=torch.float16,\n",
       "        grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1426,  0.3772, -0.0506,  ...,  0.6841,  1.2256, -0.2622],\n",
       "          [-0.4297,  0.1481, -0.7500,  ...,  0.7832, -0.6929, -0.1785],\n",
       "          [-0.4741,  0.0388,  0.0990,  ..., -1.1650, -0.2607, -1.0537],\n",
       "          ...,\n",
       "          [ 0.4841,  0.6807, -0.5513,  ..., -0.0134,  0.6621,  0.8228],\n",
       "          [-0.5566,  0.6567,  0.0994,  ...,  0.1743, -1.5332,  1.3994],\n",
       "          [ 0.4348, -1.1719, -0.1783,  ..., -1.3330, -0.0612,  0.0592]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1641,  0.3650, -0.0078,  ...,  0.6055,  1.2432, -0.2925],\n",
       "          [-0.7910,  0.4600, -0.9668,  ...,  1.1348, -0.8633, -0.1089],\n",
       "          [-0.3643,  0.1692,  0.2305,  ..., -1.5156,  0.1354, -0.9663],\n",
       "          ...,\n",
       "          [ 0.6343,  0.1548, -0.4062,  ..., -0.1240,  0.8770,  0.8008],\n",
       "          [-0.3091, -0.1338,  0.1331,  ...,  0.0178, -1.6338,  1.3906],\n",
       "          [ 0.2834, -1.4014, -0.5210,  ..., -1.0654, -0.3672, -0.1382]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1924,  0.3103,  0.0085,  ...,  0.5796,  1.2383, -0.2925],\n",
       "          [-1.0430,  0.4634, -0.9165,  ...,  1.8076, -0.5029, -0.2993],\n",
       "          [-0.4468,  0.2720,  0.0055,  ..., -1.5820,  0.1888, -0.8408],\n",
       "          ...,\n",
       "          [ 0.7988,  0.5684, -0.5371,  ..., -0.1093,  0.4893,  1.0938],\n",
       "          [-0.0889,  0.0113,  0.3264,  ...,  0.0127, -1.6387,  1.3994],\n",
       "          [ 0.1361, -1.1094, -0.3198,  ..., -1.1875, -0.4536,  0.0378]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1416,  0.2646, -0.0037,  ...,  0.5762,  1.2432, -0.3140],\n",
       "          [-1.0312,  0.3945, -1.1934,  ...,  1.6787, -0.6475, -0.1475],\n",
       "          [-0.3120,  0.5015,  0.0242,  ..., -1.6758,  0.9238, -0.6475],\n",
       "          ...,\n",
       "          [ 0.6201,  0.7417,  0.0642,  ...,  0.0569,  0.7031,  1.4453],\n",
       "          [-0.3042,  0.1711,  0.5625,  ...,  0.1453, -1.5566,  1.7744],\n",
       "          [-0.4067, -0.9209, -0.1914,  ..., -1.0400, -0.1072, -0.1133]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.0898e+00,  1.6565e-01,  1.5030e-03,  ...,  5.5420e-01,\n",
       "            1.2354e+00, -3.2471e-01],\n",
       "          [-1.3867e+00,  3.0811e-01, -1.1621e+00,  ...,  1.7168e+00,\n",
       "           -5.9668e-01, -1.4563e-01],\n",
       "          [-4.8828e-01,  6.7822e-01,  1.8872e-01,  ..., -1.8467e+00,\n",
       "            6.5625e-01, -9.0576e-01],\n",
       "          ...,\n",
       "          [ 7.5684e-01,  7.3975e-01,  1.7407e-01,  ...,  2.4426e-01,\n",
       "            6.5234e-01,  1.5322e+00],\n",
       "          [-1.8982e-01, -1.7383e-01,  6.0547e-01,  ...,  4.8071e-01,\n",
       "           -1.5186e+00,  2.1270e+00],\n",
       "          [-9.7607e-01, -5.4541e-01, -4.3799e-01,  ..., -1.6040e-01,\n",
       "           -1.8616e-01, -3.1891e-03]]], dtype=torch.float16,\n",
       "        grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1152,  0.1414, -0.0125,  ...,  0.4727,  1.2070, -0.3381],\n",
       "          [-0.9531,  0.5132, -1.4199,  ...,  1.8105, -0.6440, -0.2191],\n",
       "          [-0.5708,  0.4065, -0.3306,  ..., -1.8730,  0.7988, -0.9189],\n",
       "          ...,\n",
       "          [ 0.6577,  0.8809,  0.2329,  ...,  0.2510,  0.4932,  1.4609],\n",
       "          [-0.2722, -0.3413,  0.6665,  ...,  0.3831, -1.8223,  2.2676],\n",
       "          [-1.1406, -0.2864, -0.4382,  ..., -0.4224,  0.0197, -0.0266]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1045,  0.1320, -0.0412,  ...,  0.4211,  1.1846, -0.3367],\n",
       "          [-0.8643,  0.9038, -1.4287,  ...,  1.9229, -0.7998, -0.7192],\n",
       "          [-0.7207,  0.3584, -0.5483,  ..., -2.1250,  0.7266, -0.8389],\n",
       "          ...,\n",
       "          [ 1.0303,  0.7490, -0.1455,  ...,  0.3872,  0.5654,  1.3369],\n",
       "          [-0.1166,  0.0884,  0.2688,  ...,  0.5723, -1.6797,  2.0117],\n",
       "          [-0.9619, -0.3025, -0.3652,  ...,  0.1416, -0.0181, -0.1168]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1123,  0.1277, -0.0500,  ...,  0.3879,  1.1611, -0.3572],\n",
       "          [-1.1221,  1.0068, -2.0156,  ...,  2.1816, -0.8018, -0.7544],\n",
       "          [-0.4219,  0.0054, -0.4836,  ..., -2.3926,  0.9414, -0.5264],\n",
       "          ...,\n",
       "          [ 0.5039,  0.9541, -0.2223,  ...,  0.1827,  0.7085,  1.4326],\n",
       "          [-0.2017,  0.0485,  0.1434,  ...,  0.5884, -1.7500,  1.9795],\n",
       "          [-0.9395, -0.4707, -0.3501,  ...,  0.3787,  0.1754,  0.0391]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.0811,  0.0706, -0.0132,  ...,  0.3906,  1.1934, -0.3564],\n",
       "          [-1.7852,  0.7114, -2.4199,  ...,  2.3223, -0.5723, -1.1377],\n",
       "          [-0.4971, -0.0886, -0.6709,  ..., -2.2441,  1.0322, -0.4990],\n",
       "          ...,\n",
       "          [ 0.3638,  0.6899,  0.3274,  ...,  0.0815,  1.0166,  1.6191],\n",
       "          [-0.0349, -0.2401,  0.3650,  ...,  0.3750, -1.8281,  2.5156],\n",
       "          [-0.9985, -0.4004, -0.0579,  ...,  0.8135,  0.4187,  0.6304]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1035,  0.0377, -0.0134,  ...,  0.4099,  1.1924, -0.4014],\n",
       "          [-1.8428,  0.7559, -2.8320,  ...,  2.1738, -0.0894, -1.1504],\n",
       "          [-0.5044,  0.0975, -0.9517,  ..., -2.2480,  0.6997,  0.0566],\n",
       "          ...,\n",
       "          [ 0.4478,  0.1338,  0.3601,  ..., -0.0470,  1.2285,  1.6523],\n",
       "          [-0.1028,  0.1200,  0.6133,  ...,  0.3474, -1.9980,  2.4453],\n",
       "          [-0.5459, -0.4075,  0.1541,  ...,  1.1328,  0.5664,  0.5771]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.0986,  0.1130, -0.0668,  ...,  0.3643,  1.1729, -0.4690],\n",
       "          [-1.9756,  0.4226, -2.8457,  ...,  1.9346, -0.3086, -1.0391],\n",
       "          [-0.5781,  0.0690, -0.6812,  ..., -2.7188,  1.1006, -0.4248],\n",
       "          ...,\n",
       "          [ 0.3647,  0.0945,  0.1185,  ..., -0.5918,  0.9873,  1.8779],\n",
       "          [ 0.1062,  0.1538,  0.4829,  ..., -0.1152, -1.9707,  2.6660],\n",
       "          [-0.1470, -0.3896,  0.2236,  ...,  1.6357,  0.5654,  0.4138]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1348,  0.1204, -0.0303,  ...,  0.3975,  1.1504, -0.5010],\n",
       "          [-2.0898,  0.6860, -3.1875,  ...,  1.7617, -0.6577, -1.1562],\n",
       "          [-0.5908,  0.1753, -0.4854,  ..., -2.5781,  1.5234, -0.4563],\n",
       "          ...,\n",
       "          [ 1.0322, -0.0358,  0.3818,  ..., -0.8638,  1.1426,  1.6816],\n",
       "          [ 0.3335,  0.4597,  0.7266,  ..., -0.1454, -2.6758,  2.7285],\n",
       "          [-0.2622, -0.2544,  0.1012,  ...,  1.7490,  0.0776,  0.5967]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1553,  0.0942, -0.0245,  ...,  0.3960,  1.1299, -0.4766],\n",
       "          [-2.4316,  0.4565, -3.1289,  ...,  1.5693, -0.4805, -1.4004],\n",
       "          [-0.5234,  0.1820, -0.8828,  ..., -2.9980,  1.8398, -0.7915],\n",
       "          ...,\n",
       "          [ 1.2012, -0.3247,  0.7793,  ..., -1.1465,  1.1729,  1.4482],\n",
       "          [ 0.6890, -0.1135,  0.9341,  ..., -0.2321, -2.5215,  2.3457],\n",
       "          [-0.3840, -0.3108, -0.0140,  ...,  1.8984,  0.2764,  0.4341]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1367,  0.0422,  0.0096,  ...,  0.4153,  1.1240, -0.5273],\n",
       "          [-2.8145,  0.6670, -3.6250,  ...,  1.2148,  0.1125, -0.6279],\n",
       "          [-0.7603,  0.3186, -0.4219,  ..., -3.1465,  2.3457, -0.7349],\n",
       "          ...,\n",
       "          [ 0.7173, -0.7715,  0.8853,  ..., -1.3320,  1.3301,  1.3066],\n",
       "          [ 0.2466, -0.1675,  1.2070,  ..., -0.4009, -2.3516,  1.7725],\n",
       "          [-0.2979, -0.0339,  0.2133,  ...,  2.0410,  1.1133,  0.6826]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1504e+00,  3.1677e-02, -2.2583e-03,  ...,  4.2700e-01,\n",
       "            1.0908e+00, -5.2832e-01],\n",
       "          [-2.9648e+00,  8.4131e-01, -3.5000e+00,  ...,  9.8926e-01,\n",
       "            2.8052e-01, -3.2153e-01],\n",
       "          [-7.5098e-01,  3.2520e-01, -7.0361e-01,  ..., -2.9980e+00,\n",
       "            2.3477e+00, -6.7676e-01],\n",
       "          ...,\n",
       "          [ 6.2549e-01, -4.2261e-01,  1.1807e+00,  ..., -8.9844e-01,\n",
       "            1.0977e+00,  1.2539e+00],\n",
       "          [ 2.6392e-01,  8.6548e-02,  1.2754e+00,  ..., -2.4365e-01,\n",
       "           -2.4102e+00,  1.8643e+00],\n",
       "          [-5.2441e-01,  3.2812e-01,  2.7393e-01,  ...,  2.1523e+00,\n",
       "            1.1182e+00,  6.5088e-01]]], dtype=torch.float16,\n",
       "        grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1514,  0.0261, -0.0811,  ...,  0.4407,  1.1074, -0.5278],\n",
       "          [-3.1836,  0.9053, -3.2070,  ...,  1.2227,  0.1979, -0.1348],\n",
       "          [-0.7632,  0.6968, -1.0068,  ..., -2.5410,  2.7988, -0.5459],\n",
       "          ...,\n",
       "          [ 0.5435, -0.1189,  1.3506,  ..., -1.3047,  0.8506,  1.1035],\n",
       "          [ 0.6377,  0.0117,  1.3496,  ..., -0.5444, -2.5352,  1.9688],\n",
       "          [-0.5039,  0.7334,  0.3525,  ...,  2.2344,  0.9189,  0.2180]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1387,  0.0396, -0.0760,  ...,  0.4424,  1.1895, -0.5674],\n",
       "          [-3.0195,  0.6045, -3.1133,  ...,  1.2920,  0.2734, -0.3489],\n",
       "          [-0.7803,  0.7441, -0.5947,  ..., -2.4336,  2.8438,  0.0093],\n",
       "          ...,\n",
       "          [ 1.2266,  0.0630,  1.3877,  ..., -1.3838,  1.4141,  0.3420],\n",
       "          [ 1.0684, -0.2700,  1.4453,  ..., -0.5688, -2.3965,  1.3691],\n",
       "          [-0.8877,  0.0303,  0.7393,  ...,  2.2148,  1.0938,  0.5205]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1436,  0.0398, -0.0585,  ...,  0.4351,  1.1592, -0.5762],\n",
       "          [-3.0625,  0.1934, -2.6289,  ...,  1.2285,  0.2424, -0.0750],\n",
       "          [-0.8452,  0.8560, -0.3157,  ..., -2.0879,  2.6875,  0.2549],\n",
       "          ...,\n",
       "          [ 1.3027, -0.6323,  1.3779,  ..., -0.7939,  1.4766,  0.2937],\n",
       "          [ 1.5166, -0.6733,  1.4912,  ..., -0.3311, -2.4648,  1.1689],\n",
       "          [-1.4375, -0.0131,  0.6909,  ...,  1.8398,  1.1709,  0.4102]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1475e+00, -3.3951e-03,  1.7471e-03,  ...,  4.3628e-01,\n",
       "            1.1748e+00, -5.8887e-01],\n",
       "          [-2.5684e+00,  1.5747e-01, -2.4512e+00,  ...,  1.4980e+00,\n",
       "            7.5830e-01,  7.2205e-02],\n",
       "          [-1.0762e+00,  1.2773e+00,  4.6313e-01,  ..., -1.6699e+00,\n",
       "            2.0312e+00, -2.4133e-01],\n",
       "          ...,\n",
       "          [ 1.2051e+00, -7.0312e-01,  8.3350e-01,  ..., -4.8779e-01,\n",
       "            1.4326e+00, -1.4197e-01],\n",
       "          [ 1.0859e+00, -7.6807e-01,  1.2227e+00,  ..., -2.4292e-01,\n",
       "           -2.3867e+00,  9.2822e-01],\n",
       "          [-6.7285e-01,  5.7471e-01,  2.8296e-01,  ...,  1.9648e+00,\n",
       "            1.3096e+00,  1.0664e+00]]], dtype=torch.float16,\n",
       "        grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1328, -0.0373,  0.0359,  ...,  0.4299,  1.1621, -0.6167],\n",
       "          [-2.6797,  0.1509, -2.6133,  ...,  1.9287,  0.5928,  0.1812],\n",
       "          [-1.4951,  1.0703,  1.2471,  ..., -0.5293,  2.5840, -0.3252],\n",
       "          ...,\n",
       "          [ 1.1172, -0.7861,  0.9756,  ..., -0.6738,  1.7568, -0.6465],\n",
       "          [ 1.0244, -1.0840,  1.4980,  ...,  0.1995, -2.0781,  0.4653],\n",
       "          [-1.2637,  0.8076,  0.1653,  ...,  2.0430,  1.0039,  1.1211]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1777, -0.0572,  0.0490,  ...,  0.3738,  1.1074, -0.6968],\n",
       "          [-2.5039, -0.1608, -2.6914,  ...,  1.7559,  0.2266,  0.2283],\n",
       "          [-1.6377,  1.3438,  1.2275,  ..., -0.2898,  1.8652, -0.0425],\n",
       "          ...,\n",
       "          [ 0.9775, -0.0952,  1.1973,  ..., -0.9756,  1.5166, -0.5923],\n",
       "          [ 0.9048, -0.7280,  1.3809,  ...,  0.2939, -2.2578,  0.3523],\n",
       "          [-1.0762,  1.1777,  0.3884,  ...,  1.7520,  1.0713,  0.8145]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-0.9072, -0.5215, -0.2654,  ...,  0.4092,  1.1758, -0.8091],\n",
       "          [-2.6738, -0.5215, -2.8203,  ...,  1.8203,  0.0696, -0.2842],\n",
       "          [-2.3730,  1.2744,  0.1660,  ..., -0.4189,  1.7070, -1.2441],\n",
       "          ...,\n",
       "          [ 1.2744, -0.9888,  1.0459,  ..., -1.1055,  1.5811, -1.1670],\n",
       "          [ 1.2266, -1.6240,  0.6714,  ..., -0.0886, -1.8887,  0.0767],\n",
       "          [-1.1572,  1.2676, -0.0833,  ...,  1.6152,  1.2031,  0.6118]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.0938, -0.4475, -0.2678,  ...,  0.4297,  1.2373, -0.7588],\n",
       "          [-2.3809, -0.7051, -3.5684,  ...,  1.0850,  0.3523, -0.2415],\n",
       "          [-1.5820,  0.8257,  0.5918,  ...,  0.0253,  2.0117, -1.7539],\n",
       "          ...,\n",
       "          [ 1.4521,  0.4202,  1.6406,  ..., -0.7256,  0.2861, -3.1973],\n",
       "          [ 1.3984, -1.0898,  0.5112,  ..., -0.2462, -1.8311, -0.3560],\n",
       "          [-0.5566,  1.5889, -0.4294,  ...,  2.1250,  1.2764,  0.4514]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.1572, -0.5684, -0.3616,  ...,  0.4395,  1.3945, -0.7476],\n",
       "          [-2.1055, -0.4331, -3.9375,  ...,  1.1230,  0.4348, -0.0378],\n",
       "          [-1.7949, -0.3132,  0.4968,  ..., -0.9038,  1.5020, -2.0977],\n",
       "          ...,\n",
       "          [ 1.3076,  1.1875,  1.7803,  ..., -0.9429, -0.3877, -2.0469],\n",
       "          [ 0.7490, -0.8984,  0.3181,  ..., -0.2515, -2.1152,  0.5708],\n",
       "          [-1.2979,  2.3086, -0.7656,  ...,  1.9473,  1.4727,  0.5176]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[-1.2236, -0.4341, -0.4202,  ...,  0.7505,  1.9941, -0.8662],\n",
       "          [-2.4082, -0.2739, -3.9160,  ...,  0.9448,  0.2068, -0.0507],\n",
       "          [-1.3701, -1.1475, -0.2871,  ..., -0.7344,  1.1523, -1.4121],\n",
       "          ...,\n",
       "          [ 0.0986,  3.0586,  3.0117,  ...,  0.8774, -0.0195, -3.2637],\n",
       "          [ 0.2915, -0.3367,  0.3706,  ..., -0.0745, -2.1191,  0.6421],\n",
       "          [-0.8643,  2.4473, -0.7739,  ...,  2.3984,  2.6758,  0.5283]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[ 0.2129,  0.2417, -0.1218,  ...,  0.5444,  0.5957, -0.9619],\n",
       "          [-1.8408, -0.0330, -4.0820,  ...,  0.9053,  0.3621, -0.3342],\n",
       "          [-1.0459, -1.7910, -1.2520,  ..., -1.0293,  1.4121, -1.1396],\n",
       "          ...,\n",
       "          [ 0.6650,  1.6660,  2.4023,  ...,  0.5449, -0.0796, -3.0488],\n",
       "          [-0.4436, -0.6504, -0.4185,  ..., -0.0194, -2.2969,  0.8174],\n",
       "          [-1.3350,  2.5000, -1.2588,  ...,  2.9316,  2.6895,  0.6489]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[ 0.3589,  0.1394,  0.4341,  ...,  0.6709,  0.2358, -0.6309],\n",
       "          [-1.6484, -0.6001, -3.8262,  ...,  0.6421,  0.7373, -0.0439],\n",
       "          [-0.5176, -1.6016, -1.2998,  ..., -0.7129,  1.3115, -1.0820],\n",
       "          ...,\n",
       "          [ 1.9785,  1.3828,  1.3975,  ...,  0.0317, -1.2822, -2.3164],\n",
       "          [-0.0383, -0.1191, -0.2256,  ...,  0.7915, -2.3633,  0.9053],\n",
       "          [-2.0762,  3.0371, -1.1094,  ...,  2.7715,  2.6602, -0.0220]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[ 0.5078, -1.9209,  0.6577,  ...,  0.0291,  0.1921, -0.7871],\n",
       "          [-1.3740, -1.8447, -4.3945,  ...,  0.1184,  0.5122,  0.7466],\n",
       "          [ 0.2744, -1.8857, -1.6436,  ..., -1.0537,  1.2012, -0.6328],\n",
       "          ...,\n",
       "          [ 2.0039,  1.5391,  1.6777,  ...,  0.2703, -0.9185, -3.1406],\n",
       "          [ 0.4497,  0.3730, -0.5933,  ...,  0.7061, -2.3184,  0.6201],\n",
       "          [-1.6260,  3.8828, -0.5811,  ...,  3.1934,  2.5059, -0.5239]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[[ 0.3586, -0.7188, -0.7090,  ..., -0.4714,  1.1748, -0.7949],\n",
       "          [-0.5166, -0.2839, -1.6621,  ...,  0.3445,  0.1875,  0.3621],\n",
       "          [ 0.0491, -0.6201, -0.4238,  ..., -0.5449,  0.3972, -0.4673],\n",
       "          ...,\n",
       "          [ 0.9321,  0.4036, -0.2678,  ..., -0.2771, -0.7505, -0.5479],\n",
       "          [ 0.4263,  0.0054, -0.4688,  ...,  0.3442, -1.0615,  0.3606],\n",
       "          [-0.8218,  1.2363, -0.4419,  ...,  0.9248,  0.6450, -0.1272]]],\n",
       "        dtype=torch.float16, grad_fn=<ToCopyBackward0>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['hidden_states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
